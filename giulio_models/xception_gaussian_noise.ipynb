{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "competition_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuliovv/ANNDL_competition_1/blob/master/giulio_models/xception_gaussian_noise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knIqQUyC8bDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6af783e-6a88-42e4-f644-b9c09f9b43cc"
      },
      "source": [
        "!sudo update-alternatives --config python3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.7   2         auto mode\n",
            "  1            /usr/bin/python3.6   1         manual mode\n",
            "  2            /usr/bin/python3.7   2         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 1\n",
            "update-alternatives: using /usr/bin/python3.6 to provide /usr/bin/python3 (python3) in manual mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2fmdT158vEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9386a47-851d-48d6-e86a-55146abf4df1"
      },
      "source": [
        "!python3 --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.6.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX1pSbsV81_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc3dc90-046a-4ba5-e964-de77478ab2e5"
      },
      "source": [
        "!sudo apt install python3-pip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n",
            "  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n",
            "  python3-pkg-resources python3-secretstorage python3-setuptools python3-six\n",
            "  python3-wheel python3-xdg\n",
            "Suggested packages:\n",
            "  python-crypto-doc python-cryptography-doc python3-cryptography-vectors\n",
            "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0\n",
            "  python-secretstorage-doc python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n",
            "  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n",
            "  python3-pip python3-pkg-resources python3-secretstorage python3-setuptools\n",
            "  python3-six python3-wheel python3-xdg\n",
            "0 upgraded, 15 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 2,882 kB of archives.\n",
            "After this operation, 8,886 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.5 [1,653 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-asn1crypto all 0.24.0-1 [72.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-cffi-backend amd64 1.11.5-1 [64.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-cryptography amd64 2.1.4-1ubuntu1.4 [220 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-secretstorage all 2.3.1-2 [12.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyring all 10.6.0-1 [26.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyrings.alt all 3.0-1 [16.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pip all 9.0.1-2.3~ubuntu1.18.04.5 [114 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wheel all 0.30.0-0.2 [36.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-xdg all 0.25-4ubuntu1.1 [31.3 kB]\n",
            "Fetched 2,882 kB in 1s (2,086 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 15.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Selecting previously unselected package python3-asn1crypto.\n",
            "Preparing to unpack .../01-python3-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python3-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python3-cffi-backend.\n",
            "Preparing to unpack .../02-python3-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python3-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python3-crypto.\n",
            "Preparing to unpack .../03-python3-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
            "Unpacking python3-crypto (2.6.1-8ubuntu2) ...\n",
            "Selecting previously unselected package python3-idna.\n",
            "Preparing to unpack .../04-python3-idna_2.6-1_all.deb ...\n",
            "Unpacking python3-idna (2.6-1) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../05-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-cryptography.\n",
            "Preparing to unpack .../06-python3-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Selecting previously unselected package python3-secretstorage.\n",
            "Preparing to unpack .../07-python3-secretstorage_2.3.1-2_all.deb ...\n",
            "Unpacking python3-secretstorage (2.3.1-2) ...\n",
            "Selecting previously unselected package python3-keyring.\n",
            "Preparing to unpack .../08-python3-keyring_10.6.0-1_all.deb ...\n",
            "Unpacking python3-keyring (10.6.0-1) ...\n",
            "Selecting previously unselected package python3-keyrings.alt.\n",
            "Preparing to unpack .../09-python3-keyrings.alt_3.0-1_all.deb ...\n",
            "Unpacking python3-keyrings.alt (3.0-1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../10-python3-pip_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
            "Unpacking python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../11-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../12-python3-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python3-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../13-python3-wheel_0.30.0-0.2_all.deb ...\n",
            "Unpacking python3-wheel (0.30.0-0.2) ...\n",
            "Selecting previously unselected package python3-xdg.\n",
            "Preparing to unpack .../14-python3-xdg_0.25-4ubuntu1.1_all.deb ...\n",
            "Unpacking python3-xdg (0.25-4ubuntu1.1) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Setting up python3-cffi-backend (1.11.5-1) ...\n",
            "Setting up python3-crypto (2.6.1-8ubuntu2) ...\n",
            "Setting up python3-idna (2.6-1) ...\n",
            "Setting up python3-xdg (0.25-4ubuntu1.1) ...\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "Setting up python3-wheel (0.30.0-0.2) ...\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "Setting up python3-asn1crypto (0.24.0-1) ...\n",
            "Setting up python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Setting up python3-setuptools (39.0.1-2) ...\n",
            "Setting up python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Setting up python3-keyrings.alt (3.0-1) ...\n",
            "Setting up python3-secretstorage (2.3.1-2) ...\n",
            "Setting up python3-keyring (10.6.0-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-35gnQG8yoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a8bba1-4684-4b95-96c2-a443e9ce179c"
      },
      "source": [
        "import os\n",
        "\n",
        "colab = \"True\" #@param ['True','False']\n",
        "if colab == \"True\":\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "  %cd /gdrive/MyDrive/Colab Notebooks\n",
        "  if not os.path.isdir('training'):\n",
        "    !unzip dataset.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kad8mvnp85ML"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voCaRwS49Mol"
      },
      "source": [
        "dataset_dir = 'training'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw7zb8mT9Sk3"
      },
      "source": [
        "Let the game begin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TmhNrm6EnAo"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mba3lGlpAxXd"
      },
      "source": [
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMq2iAFBFN4Z"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC8765_k1smh"
      },
      "source": [
        "labels = ['Apple','Blueberry','Cherry','Corn','Grape','Orange','Peach','Pepper','Potato','Raspberry','Soybean','Squash','Strawberry','Tomato']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsUbDe48D-Dt",
        "outputId": "9ed6b9a2-bdb3-4b26-c2c4-905befa0463d"
      },
      "source": [
        "y = tf.keras.utils.to_categorical(range(len(labels)))\n",
        "y"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSqVl1baOwjs"
      },
      "source": [
        "import shutil\n",
        "\n",
        "get_plants = False\n",
        "\n",
        "if not \"test\" in os.listdir():\n",
        "  print(\"No test directory!\")\n",
        "  for label in labels:\n",
        "    print(label)\n",
        "    image_names = [pic for pic in os.listdir(\"training/\"+label)]\n",
        "    train_images, test_images = train_test_split(image_names, test_size=0.05)\n",
        "    if not 'test/'+label in os.listdir():\n",
        "      try:\n",
        "        os.makedirs(os.path.abspath(os.getcwd())+'/test/'+label+'/')\n",
        "      except OSError:\n",
        "        print(\"Failed to create a dir for \", '/test/'+label+'/')\n",
        "      else:\n",
        "        print(\"Success creating folder \", label)\n",
        "    for name in test_images:\n",
        "      shutil.move(os.path.abspath(os.getcwd())+'/training/'+label+'/'+name, os.path.abspath(os.getcwd())+'/test/'+label+'/'+name)\n",
        "  print(\"Transfered all testing data!\")\n",
        "\n",
        "if get_plants:\n",
        "  ! pip install -q tfds-nightly\n",
        "  import tensorflow_datasets as tfds\n",
        "  from PIL import Image\n",
        "  ds = tfds.load('plant_village', split='train')\n",
        "  builder = tfds.builder('plant_village')\n",
        "  info = builder.info\n",
        "  labels_tf = info.features[\"label\"].names\n",
        "  if not 'test_expanded/' in os.listdir():\n",
        "      try:\n",
        "        os.makedirs(os.path.abspath(os.getcwd())+'/test_expanded/')\n",
        "      except OSError:\n",
        "        print(\"Failed to create a dir for /test_expanded/\")\n",
        "      else:\n",
        "        print(\"Success creating folder test_expanded\")\n",
        "  image_number = 54303\n",
        "  ds = ds.take(54303)\n",
        "  for el in ds:\n",
        "    label_new_ds = labels_tf[el[\"label\"].numpy()]\n",
        "    for just_fruit_name in labels:\n",
        "      if just_fruit_name in label_new_ds:\n",
        "        if not just_fruit_name in os.listdir(\"test_expanded\"):\n",
        "          try:\n",
        "            os.makedirs(os.path.abspath(os.getcwd())+'/test_expanded/'+just_fruit_name+'/')\n",
        "          except OSError:\n",
        "            print(\"Failed to create a dir for \", '/test_expanded/'+just_fruit_name+'/')\n",
        "          else:\n",
        "            print(\"Success creating folder \", just_fruit_name)\n",
        "        im = Image.fromarray(el[\"image\"].numpy())\n",
        "        im.save(os.path.abspath(os.getcwd())+'/test_expanded/'+just_fruit_name+\"/\"+str(image_number)+\".jpeg\")\n",
        "        break\n",
        "    if image_number % 1000 == 0:\n",
        "      print(image_number)\n",
        "    image_number += 1\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WDFJ3xEckxa"
      },
      "source": [
        "import random\n",
        "\n",
        "def preproc(img):\n",
        "  '''Add random noise to an image'''\n",
        "  VARIABILITY = 50\n",
        "  deviation = VARIABILITY*random.random()\n",
        "  noise = np.random.normal(0, deviation, img.shape)\n",
        "  img += noise\n",
        "  np.clip(img, 0., 255.)\n",
        "  X = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "  return X"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO-nIcaRTU1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b90c61-71a2-4d58-b5f2-c2a93963eb6b"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "VALIDATE_BATCH_SIZE = BATCH_SIZE\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "## when rotating some pixels remain unfilled, to fill them the default function is to take the \"nearest pixel color\", this maybe screws up the learning process so I left it for later training\n",
        "                                    rotation_range=90,\n",
        "                                    fill_mode='nearest',\n",
        "                                    brightness_range=(0.2,1.8),\n",
        "                                    channel_shift_range=150,\n",
        "                                    shear_range=0.7,\n",
        "                                    zoom_range=0.5,\n",
        "                                    width_shift_range=0.3, \n",
        "                                    height_shift_range=0.3,\n",
        "                                    horizontal_flip=True, \n",
        "                                    vertical_flip=True,\n",
        "                                    validation_split=0.05,\n",
        "                                    preprocessing_function=tf.keras.applications.xception.preprocess_input) # VGG16 preprocessing\n",
        "test_generator = ImageDataGenerator(preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
        "\n",
        "traingen = train_generator.flow_from_directory('training',\n",
        "                                              target_size=(256, 256),\n",
        "                                              class_mode='categorical',\n",
        "                                              classes=labels,\n",
        "                                              subset='training',\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              seed=42)\n",
        "\n",
        "validgen = train_generator.flow_from_directory('training',\n",
        "                                              target_size=(256, 256),\n",
        "                                              class_mode='categorical',\n",
        "                                              classes=labels,\n",
        "                                              subset='validation',\n",
        "                                              batch_size=VALIDATE_BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              seed=42)\n",
        "\n",
        "testgen = test_generator.flow_from_directory('test',\n",
        "                                            target_size=(256, 256),\n",
        "                                            class_mode='categorical',\n",
        "                                            classes=labels,\n",
        "                                            batch_size=1,\n",
        "                                            shuffle=False,\n",
        "                                            seed=42)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15720 images belonging to 14 classes.\n",
            "Found 819 images belonging to 14 classes.\n",
            "Found 877 images belonging to 14 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2xDRSNudWsz"
      },
      "source": [
        "from  sklearn.utils import class_weight"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-qu2NNNdGYp"
      },
      "source": [
        "class_weights = class_weight.compute_class_weight(\n",
        "            class_weight='balanced',\n",
        "            classes=np.unique(traingen.classes), \n",
        "            y=traingen.classes)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1qX2Yha_XmP"
      },
      "source": [
        "n_steps = traingen.samples / BATCH_SIZE\n",
        "n_val_steps = validgen.samples / VALIDATE_BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeECwxYABRW7"
      },
      "source": [
        "# create the base pre-trained model\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=(256, 256,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po279iIMCB8Z"
      },
      "source": [
        "n_classes = len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CQO37g_H82e"
      },
      "source": [
        "load = False\n",
        "\n",
        "if load:\n",
        "  model = tf.keras.models.load_model(\"xception_only_top\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3zgOshuBT7o"
      },
      "source": [
        "from keras.layers import LeakyReLU\n",
        "lrelu = lambda x: tf.keras.activations.relu(x, alpha=0.01)\n",
        "\n",
        "if not load:\n",
        "  inputs = keras.Input(shape=(256, 256, 3))\n",
        "  inputs = tf.keras.layers.GaussianNoise(20)(inputs)\n",
        "  x = base_model(inputs, training=False)\n",
        "  # x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "  # add a global spatial average pooling layer\n",
        "  # x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = tf.keras.layers.Flatten()(x)\n",
        "  x = tf.keras.layers.Dropout(0.2)(x)\n",
        "  # let's add a fully-connected layer\n",
        "  x = Dense(1024, activation=lrelu, name=\"first\")(x)\n",
        "  x = Dense(512, activation=lrelu, name=\"second\")(x)\n",
        "  x = tf.keras.layers.Flatten()(x)\n",
        "  x = tf.keras.layers.Dropout(0.8)(x)\n",
        "  x = Dense(512, activation=lrelu, name=\"third\")(x)\n",
        "  # and a logistic layer -- let's say we have n_classes classes\n",
        "  predictions = Dense(n_classes, activation='softmax', name=\"last\")(x)\n",
        "\n",
        "  # this is the model we will train\n",
        "  model = Model(inputs=inputs, outputs=predictions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wsxV1pEB5Nq"
      },
      "source": [
        "if not load:\n",
        "\n",
        "  # first: train only the top layers (which were randomly initialized)\n",
        "  # i.e. freeze all convolutional InceptionV3 layers\n",
        "  for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "  # compile the model (should be done *after* setting layers to non-trainable)\n",
        "  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Iw3p86sGTXh"
      },
      "source": [
        "callbacks = []\n",
        "\n",
        "early_stop = True\n",
        "if early_stop:\n",
        "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)\n",
        "    callbacks.append(es_callback)\n",
        "    \n",
        "#LRPlateau\n",
        "lr_plateau_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    min_lr=0,\n",
        ")  \n",
        "\n",
        "callbacks.append(lr_plateau_callback)\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\", histogram_freq=1)\n",
        "\n",
        "callbacks.append(tensorboard_callback)\n",
        "\n",
        "backup = tf.keras.callbacks.experimental.BackupAndRestore(\n",
        "    \"xception_top_only_backup\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQXQ6gs7P-m9"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnoXtvRUP_Dz"
      },
      "source": [
        "%tensorboard --logdir \"./logs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfNRHFoGCRYR"
      },
      "source": [
        "if not load:\n",
        "  # train the model on the new data for a few epochs\n",
        "  # 18 epochs with dropout\n",
        "  model.fit(traingen, epochs=12, steps_per_epoch=n_steps, batch_size=BATCH_SIZE, validation_data=validgen, callbacks=callbacks+[backup], class_weight=class_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JplAsf-d9Hi"
      },
      "source": [
        "if not load:\n",
        "  model.save(\"xception_only_top\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqiycAJLJIrG"
      },
      "source": [
        "# at this point, the top layers are well trained and we can start fine-tuning\n",
        "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
        "# and train the remaining top layers.\n",
        "\n",
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D6lxpfHi6k8"
      },
      "source": [
        "load_second = False\n",
        "if load_second:\n",
        "  model = tf.keras.models.load_model(\"xception\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDbD1NeQYMDA"
      },
      "source": [
        "if not load_second:\n",
        "  # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "  # the first 249 layers and unfreeze the rest:\n",
        "  for layer in model.layers[:50]:\n",
        "    layer.trainable = False\n",
        "  for layer in model.layers[50:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "  # we need to recompile the model for these modifications to take effect\n",
        "  # we use SGD with a low learning rate\n",
        "  from tensorflow.keras.optimizers import Adam\n",
        "  model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "backup2 = tf.keras.callbacks.experimental.BackupAndRestore(\n",
        "    \"xception_second_part_backup\"\n",
        ")\n",
        "\n",
        "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
        "# alongside the top Dense layers\n",
        "model.fit(traingen, epochs=15, steps_per_epoch=n_steps,  batch_size=BATCH_SIZE, validation_data=validgen, callbacks=callbacks+[backup2], class_weight=class_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXeZeBLzeDz3"
      },
      "source": [
        "model.save(\"xception\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeTl15C289ZK"
      },
      "source": [
        "model.evaluate(testgen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJbPurSt-xl2"
      },
      "source": [
        "# Further fitting, very low lr\n",
        "super_final_fit = False\n",
        "if super_final_fit:\n",
        "  model = tf.keras.models.load_model(\"xception\")\n",
        "\n",
        "  # Unfreeze also your mom\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "  # Lr so low\n",
        "  from tensorflow.keras.optimizers import Adam\n",
        "  model.compile(optimizer=Adam(learning_rate=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jGoSrICSQsr"
      },
      "source": [
        "if super_final_fit:\n",
        "  model.fit(traingen, epochs=13, steps_per_epoch=n_steps,  batch_size=BATCH_SIZE, validation_data=validgen, class_weight=class_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeVywZgllaTi"
      },
      "source": [
        "if super_final_fit:\n",
        "  model.save(\"xception_super_final\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBLuZvP6yMz6"
      },
      "source": [
        "load_super_final_fit = True\n",
        "if load_super_final_fit:\n",
        "  super_final_fit = True\n",
        "  model = tf.keras.models.load_model(\"xception_super_final\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4UbdyDolCap"
      },
      "source": [
        "if super_final_fit:\n",
        "  from keras import backend as K\n",
        "  K.set_value(model.optimizer.learning_rate, 5e-6)\n",
        "  model.fit(traingen, epochs=15, steps_per_epoch=n_steps,  batch_size=BATCH_SIZE, validation_data=validgen)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}