{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "competition_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuliovv/ANNDL_competition_1/blob/master/giulio_models/xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-35gnQG8yoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4afeb51d-125e-4895-e58a-3d92000279d4"
      },
      "source": [
        "import os\n",
        "\n",
        "colab = \"True\" #@param ['True','False']\n",
        "if colab == \"True\":\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "  %cd /gdrive/MyDrive/Colab Notebooks\n",
        "  if not os.path.isdir('training'):\n",
        "    !unzip dataset.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kad8mvnp85ML"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voCaRwS49Mol"
      },
      "source": [
        "dataset_dir = 'training'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw7zb8mT9Sk3"
      },
      "source": [
        "Let the game begin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TmhNrm6EnAo"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mba3lGlpAxXd"
      },
      "source": [
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMq2iAFBFN4Z"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC8765_k1smh"
      },
      "source": [
        "labels = ['Apple','Blueberry','Cherry','Corn','Grape','Orange','Peach','Pepper','Potato','Raspberry','Soybean','Squash','Strawberry','Tomato']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsUbDe48D-Dt",
        "outputId": "95bb5c78-254a-407c-f11d-46488c45f135"
      },
      "source": [
        "y = tf.keras.utils.to_categorical(range(len(labels)))\n",
        "y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaXbxwZBwvwb"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSqVl1baOwjs"
      },
      "source": [
        "import shutil\n",
        "\n",
        "get_plants = False\n",
        "\n",
        "if not \"test\" in os.listdir():\n",
        "  print(\"No test directory!\")\n",
        "  for label in labels:\n",
        "    print(label)\n",
        "    image_names = [pic for pic in os.listdir(\"training/\"+label)]\n",
        "    train_images, test_images = train_test_split(image_names, test_size=0.05)\n",
        "    if not 'test/'+label in os.listdir():\n",
        "      try:\n",
        "        os.makedirs(os.path.abspath(os.getcwd())+'/test/'+label+'/')\n",
        "      except OSError:\n",
        "        print(\"Failed to create a dir for \", '/test/'+label+'/')\n",
        "      else:\n",
        "        print(\"Success creating folder \", label)\n",
        "    for name in test_images:\n",
        "      shutil.move(os.path.abspath(os.getcwd())+'/training/'+label+'/'+name, os.path.abspath(os.getcwd())+'/test/'+label+'/'+name)\n",
        "  print(\"Transfered all testing data!\")\n",
        "\n",
        "if get_plants:\n",
        "  ! pip install -q tfds-nightly\n",
        "  import tensorflow_datasets as tfds\n",
        "  from PIL import Image\n",
        "  ds = tfds.load('plant_village', split='train')\n",
        "  builder = tfds.builder('plant_village')\n",
        "  info = builder.info\n",
        "  labels_tf = info.features[\"label\"].names\n",
        "  if not 'test_expanded/' in os.listdir():\n",
        "      try:\n",
        "        os.makedirs(os.path.abspath(os.getcwd())+'/test_expanded/')\n",
        "      except OSError:\n",
        "        print(\"Failed to create a dir for /test_expanded/\")\n",
        "      else:\n",
        "        print(\"Success creating folder test_expanded\")\n",
        "  image_number = 54303\n",
        "  ds = ds.take(54303)\n",
        "  for el in ds:\n",
        "    label_new_ds = labels_tf[el[\"label\"].numpy()]\n",
        "    for just_fruit_name in labels:\n",
        "      if just_fruit_name in label_new_ds:\n",
        "        if not just_fruit_name in os.listdir(\"test_expanded\"):\n",
        "          try:\n",
        "            os.makedirs(os.path.abspath(os.getcwd())+'/test_expanded/'+just_fruit_name+'/')\n",
        "          except OSError:\n",
        "            print(\"Failed to create a dir for \", '/test_expanded/'+just_fruit_name+'/')\n",
        "          else:\n",
        "            print(\"Success creating folder \", just_fruit_name)\n",
        "        im = Image.fromarray(el[\"image\"].numpy())\n",
        "        im.save(os.path.abspath(os.getcwd())+'/test_expanded/'+just_fruit_name+\"/\"+str(image_number)+\".jpeg\")\n",
        "        break\n",
        "    if image_number % 1000 == 0:\n",
        "      print(image_number)\n",
        "    image_number += 1\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WDFJ3xEckxa"
      },
      "source": [
        "import random\n",
        "\n",
        "def preproc(img):\n",
        "  '''Add random noise to an image'''\n",
        "  VARIABILITY = 50\n",
        "  deviation = VARIABILITY*random.random()\n",
        "  noise = np.random.normal(0, deviation, img.shape)\n",
        "  img += noise\n",
        "  np.clip(img, 0., 255.)\n",
        "  X = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "  return X"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO-nIcaRTU1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "485bd5cc-d48c-4735-b1a8-54ef92991fa7"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "VALIDATE_BATCH_SIZE = BATCH_SIZE\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "## when rotating some pixels remain unfilled, to fill them the default function is to take the \"nearest pixel color\", this maybe screws up the learning process so I left it for later training\n",
        "                                    rotation_range=90,\n",
        "                                    fill_mode='nearest',\n",
        "                                    brightness_range=(0.2,1.8),\n",
        "                                    channel_shift_range=150,\n",
        "                                    shear_range=0.5,\n",
        "                                    zoom_range=0.5,\n",
        "                                    width_shift_range=0.3, \n",
        "                                    height_shift_range=0.3,\n",
        "                                    horizontal_flip=True, \n",
        "                                    vertical_flip=True,\n",
        "                                    validation_split=0.1,\n",
        "                                    preprocessing_function=tf.keras.applications.xception.preprocess_input) # VGG16 preprocessing\n",
        "test_generator = ImageDataGenerator(preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
        "\n",
        "traingen = train_generator.flow_from_directory('training',\n",
        "                                              target_size=(256, 256),\n",
        "                                              class_mode='categorical',\n",
        "                                              classes=labels,\n",
        "                                              subset='training',\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              seed=42)\n",
        "\n",
        "validgen = train_generator.flow_from_directory('training',\n",
        "                                              target_size=(256, 256),\n",
        "                                              class_mode='categorical',\n",
        "                                              classes=labels,\n",
        "                                              subset='validation',\n",
        "                                              batch_size=VALIDATE_BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              seed=42)\n",
        "\n",
        "testgen = test_generator.flow_from_directory('test',\n",
        "                                            target_size=(256, 256),\n",
        "                                            class_mode='categorical',\n",
        "                                            classes=labels,\n",
        "                                            batch_size=1,\n",
        "                                            shuffle=False,\n",
        "                                            seed=42)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14892 images belonging to 14 classes.\n",
            "Found 1647 images belonging to 14 classes.\n",
            "Found 877 images belonging to 14 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1qX2Yha_XmP"
      },
      "source": [
        "n_steps = traingen.samples / BATCH_SIZE\n",
        "n_val_steps = validgen.samples / VALIDATE_BATCH_SIZE"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeECwxYABRW7"
      },
      "source": [
        "# create the base pre-trained model\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=(256, 256,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po279iIMCB8Z"
      },
      "source": [
        "n_classes = len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CQO37g_H82e"
      },
      "source": [
        "load = True\n",
        "\n",
        "if load:\n",
        "  model = tf.keras.models.load_model(\"xception_only_top\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3zgOshuBT7o"
      },
      "source": [
        "from keras.layers import LeakyReLU\n",
        "lrelu = lambda x: tf.keras.activations.relu(x, alpha=0.01)\n",
        "\n",
        "if not load:\n",
        "  # add a global spatial average pooling layer\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = tf.keras.layers.Flatten()(x)\n",
        "  x = tf.keras.layers.Dropout(0.7)(x)\n",
        "  # let's add a fully-connected layer\n",
        "  x = Dense(1024, activation=lrelu, name=\"first\")(x)\n",
        "  x = Dense(512, activation=lrelu, name=\"second\")(x)\n",
        "  x = Dense(512, activation=lrelu, name=\"third\")(x)\n",
        "  # and a logistic layer -- let's say we have n_classes classes\n",
        "  predictions = Dense(n_classes, activation='softmax', name=\"last\")(x)\n",
        "\n",
        "  # this is the model we will train\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wsxV1pEB5Nq"
      },
      "source": [
        "if not load:\n",
        "\n",
        "  # first: train only the top layers (which were randomly initialized)\n",
        "  # i.e. freeze all convolutional InceptionV3 layers\n",
        "  for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
        "\n",
        "  # compile the model (should be done *after* setting layers to non-trainable)\n",
        "  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Iw3p86sGTXh"
      },
      "source": [
        "callbacks = []\n",
        "\n",
        "early_stop = True\n",
        "if early_stop:\n",
        "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)\n",
        "    callbacks.append(es_callback)\n",
        "    \n",
        "#LRPlateau\n",
        "lr_plateau_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    min_lr=0,\n",
        ")  \n",
        "\n",
        "callbacks.append(lr_plateau_callback)\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\", histogram_freq=1)\n",
        "\n",
        "callbacks.append(tensorboard_callback)\n",
        "\n",
        "backup = tf.keras.callbacks.experimental.BackupAndRestore(\n",
        "    \"xception_top_only_backup\"\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQXQ6gs7P-m9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8fd1c76-fc3d-41ea-8c2c-3ef46f1d3dbb"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnoXtvRUP_Dz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9e6a73f-0fe9-4b3c-fc78-431afd9a7580"
      },
      "source": [
        "%tensorboard --logdir \"./logs\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 1340."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfNRHFoGCRYR"
      },
      "source": [
        "if not load:\n",
        "  # train the model on the new data for a few epochs\n",
        "  # 18 epochs with dropout\n",
        "  model.fit(traingen, epochs=12, steps_per_epoch=n_steps, batch_size=BATCH_SIZE, validation_data=validgen, callbacks=callbacks+[backup])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JplAsf-d9Hi"
      },
      "source": [
        "if not load:\n",
        "  model.save(\"xception_only_top\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqiycAJLJIrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf6c029-9d6f-4f41-cbfd-c113fd8e96a5"
      },
      "source": [
        "# at this point, the top layers are well trained and we can start fine-tuning\n",
        "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
        "# and train the remaining top layers.\n",
        "\n",
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_2\n",
            "1 block1_conv1\n",
            "2 block1_conv1_bn\n",
            "3 block1_conv1_act\n",
            "4 block1_conv2\n",
            "5 block1_conv2_bn\n",
            "6 block1_conv2_act\n",
            "7 block2_sepconv1\n",
            "8 block2_sepconv1_bn\n",
            "9 block2_sepconv2_act\n",
            "10 block2_sepconv2\n",
            "11 block2_sepconv2_bn\n",
            "12 conv2d_4\n",
            "13 block2_pool\n",
            "14 batch_normalization_4\n",
            "15 add_12\n",
            "16 block3_sepconv1_act\n",
            "17 block3_sepconv1\n",
            "18 block3_sepconv1_bn\n",
            "19 block3_sepconv2_act\n",
            "20 block3_sepconv2\n",
            "21 block3_sepconv2_bn\n",
            "22 conv2d_5\n",
            "23 block3_pool\n",
            "24 batch_normalization_5\n",
            "25 add_13\n",
            "26 block4_sepconv1_act\n",
            "27 block4_sepconv1\n",
            "28 block4_sepconv1_bn\n",
            "29 block4_sepconv2_act\n",
            "30 block4_sepconv2\n",
            "31 block4_sepconv2_bn\n",
            "32 conv2d_6\n",
            "33 block4_pool\n",
            "34 batch_normalization_6\n",
            "35 add_14\n",
            "36 block5_sepconv1_act\n",
            "37 block5_sepconv1\n",
            "38 block5_sepconv1_bn\n",
            "39 block5_sepconv2_act\n",
            "40 block5_sepconv2\n",
            "41 block5_sepconv2_bn\n",
            "42 block5_sepconv3_act\n",
            "43 block5_sepconv3\n",
            "44 block5_sepconv3_bn\n",
            "45 add_15\n",
            "46 block6_sepconv1_act\n",
            "47 block6_sepconv1\n",
            "48 block6_sepconv1_bn\n",
            "49 block6_sepconv2_act\n",
            "50 block6_sepconv2\n",
            "51 block6_sepconv2_bn\n",
            "52 block6_sepconv3_act\n",
            "53 block6_sepconv3\n",
            "54 block6_sepconv3_bn\n",
            "55 add_16\n",
            "56 block7_sepconv1_act\n",
            "57 block7_sepconv1\n",
            "58 block7_sepconv1_bn\n",
            "59 block7_sepconv2_act\n",
            "60 block7_sepconv2\n",
            "61 block7_sepconv2_bn\n",
            "62 block7_sepconv3_act\n",
            "63 block7_sepconv3\n",
            "64 block7_sepconv3_bn\n",
            "65 add_17\n",
            "66 block8_sepconv1_act\n",
            "67 block8_sepconv1\n",
            "68 block8_sepconv1_bn\n",
            "69 block8_sepconv2_act\n",
            "70 block8_sepconv2\n",
            "71 block8_sepconv2_bn\n",
            "72 block8_sepconv3_act\n",
            "73 block8_sepconv3\n",
            "74 block8_sepconv3_bn\n",
            "75 add_18\n",
            "76 block9_sepconv1_act\n",
            "77 block9_sepconv1\n",
            "78 block9_sepconv1_bn\n",
            "79 block9_sepconv2_act\n",
            "80 block9_sepconv2\n",
            "81 block9_sepconv2_bn\n",
            "82 block9_sepconv3_act\n",
            "83 block9_sepconv3\n",
            "84 block9_sepconv3_bn\n",
            "85 add_19\n",
            "86 block10_sepconv1_act\n",
            "87 block10_sepconv1\n",
            "88 block10_sepconv1_bn\n",
            "89 block10_sepconv2_act\n",
            "90 block10_sepconv2\n",
            "91 block10_sepconv2_bn\n",
            "92 block10_sepconv3_act\n",
            "93 block10_sepconv3\n",
            "94 block10_sepconv3_bn\n",
            "95 add_20\n",
            "96 block11_sepconv1_act\n",
            "97 block11_sepconv1\n",
            "98 block11_sepconv1_bn\n",
            "99 block11_sepconv2_act\n",
            "100 block11_sepconv2\n",
            "101 block11_sepconv2_bn\n",
            "102 block11_sepconv3_act\n",
            "103 block11_sepconv3\n",
            "104 block11_sepconv3_bn\n",
            "105 add_21\n",
            "106 block12_sepconv1_act\n",
            "107 block12_sepconv1\n",
            "108 block12_sepconv1_bn\n",
            "109 block12_sepconv2_act\n",
            "110 block12_sepconv2\n",
            "111 block12_sepconv2_bn\n",
            "112 block12_sepconv3_act\n",
            "113 block12_sepconv3\n",
            "114 block12_sepconv3_bn\n",
            "115 add_22\n",
            "116 block13_sepconv1_act\n",
            "117 block13_sepconv1\n",
            "118 block13_sepconv1_bn\n",
            "119 block13_sepconv2_act\n",
            "120 block13_sepconv2\n",
            "121 block13_sepconv2_bn\n",
            "122 conv2d_7\n",
            "123 block13_pool\n",
            "124 batch_normalization_7\n",
            "125 add_23\n",
            "126 block14_sepconv1\n",
            "127 block14_sepconv1_bn\n",
            "128 block14_sepconv1_act\n",
            "129 block14_sepconv2\n",
            "130 block14_sepconv2_bn\n",
            "131 block14_sepconv2_act\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D6lxpfHi6k8"
      },
      "source": [
        "load_second = False\n",
        "if load_second:\n",
        "  model = tf.keras.models.load_model(\"xception\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDbD1NeQYMDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a01d2a9b-16a3-4537-bf93-6e5b36076c40"
      },
      "source": [
        "if not load_second:\n",
        "  # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "  # the first 249 layers and unfreeze the rest:\n",
        "  for layer in model.layers[:50]:\n",
        "    layer.trainable = False\n",
        "  for layer in model.layers[50:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "  # we need to recompile the model for these modifications to take effect\n",
        "  # we use SGD with a low learning rate\n",
        "  from tensorflow.keras.optimizers import Adam\n",
        "  model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "backup2 = tf.keras.callbacks.experimental.BackupAndRestore(\n",
        "    \"xception_second_part_backup\"\n",
        ")\n",
        "\n",
        "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
        "# alongside the top Dense layers\n",
        "model.fit(traingen, epochs=15, steps_per_epoch=n_steps,  batch_size=BATCH_SIZE, validation_data=validgen, callbacks=callbacks+[backup2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "206/206 [==============================] - 496s 2s/step - loss: 0.4273 - accuracy: 0.8667 - val_loss: 0.4123 - val_accuracy: 0.8773 - lr: 1.0000e-04\n",
            "Epoch 2/15\n",
            "206/206 [==============================] - 481s 2s/step - loss: 0.1971 - accuracy: 0.9355 - val_loss: 0.2413 - val_accuracy: 0.9261 - lr: 1.0000e-04\n",
            "Epoch 3/15\n",
            "206/206 [==============================] - 478s 2s/step - loss: 0.1430 - accuracy: 0.9552 - val_loss: 0.2471 - val_accuracy: 0.9221 - lr: 1.0000e-04\n",
            "Epoch 4/15\n",
            "206/206 [==============================] - 477s 2s/step - loss: 0.1228 - accuracy: 0.9605 - val_loss: 0.1880 - val_accuracy: 0.9446 - lr: 1.0000e-04\n",
            "Epoch 5/15\n",
            "206/206 [==============================] - 478s 2s/step - loss: 0.0988 - accuracy: 0.9680 - val_loss: 0.2323 - val_accuracy: 0.9315 - lr: 1.0000e-04\n",
            "Epoch 6/15\n",
            "206/206 [==============================] - 478s 2s/step - loss: 0.1005 - accuracy: 0.9671 - val_loss: 0.1774 - val_accuracy: 0.9452 - lr: 1.0000e-04\n",
            "Epoch 7/15\n",
            "206/206 [==============================] - 478s 2s/step - loss: 0.0854 - accuracy: 0.9733 - val_loss: 0.1700 - val_accuracy: 0.9537 - lr: 1.0000e-04\n",
            "Epoch 8/15\n",
            "206/206 [==============================] - 479s 2s/step - loss: 0.0755 - accuracy: 0.9760 - val_loss: 0.1734 - val_accuracy: 0.9509 - lr: 1.0000e-04\n",
            "Epoch 9/15\n",
            "206/206 [==============================] - 478s 2s/step - loss: 0.0721 - accuracy: 0.9772 - val_loss: 0.1767 - val_accuracy: 0.9509 - lr: 1.0000e-04\n",
            "Epoch 10/15\n",
            "206/206 [==============================] - 483s 2s/step - loss: 0.0711 - accuracy: 0.9763 - val_loss: 0.1724 - val_accuracy: 0.9524 - lr: 1.0000e-04\n",
            "Epoch 11/15\n",
            "206/206 [==============================] - 479s 2s/step - loss: 0.0609 - accuracy: 0.9804 - val_loss: 0.1216 - val_accuracy: 0.9640 - lr: 2.0000e-05\n",
            "Epoch 12/15\n",
            "206/206 [==============================] - 478s 2s/step - loss: 0.0511 - accuracy: 0.9832 - val_loss: 0.1040 - val_accuracy: 0.9700 - lr: 2.0000e-05\n",
            "Epoch 13/15\n",
            "206/206 [==============================] - 479s 2s/step - loss: 0.0484 - accuracy: 0.9844 - val_loss: 0.0997 - val_accuracy: 0.9718 - lr: 2.0000e-05\n",
            "Epoch 14/15\n",
            "206/206 [==============================] - 478s 2s/step - loss: 0.0456 - accuracy: 0.9842 - val_loss: 0.1064 - val_accuracy: 0.9700 - lr: 2.0000e-05\n",
            "Epoch 15/15\n",
            "206/206 [==============================] - 476s 2s/step - loss: 0.0441 - accuracy: 0.9856 - val_loss: 0.1172 - val_accuracy: 0.9652 - lr: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1a2de61610>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXeZeBLzeDz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b06682-754d-42e1-a284-e0c92d8afb28"
      },
      "source": [
        "model.save(\"xception\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: xception/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n",
            "WARNING:absl:<keras.saving.saved_model.load.Dense object at 0x7f1a2dd36d90> has the same name 'Dense' as a built-in Keras object. Consider renaming <class 'keras.saving.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.saving.saved_model.load.Dense object at 0x7f1a2dd3ad90> has the same name 'Dense' as a built-in Keras object. Consider renaming <class 'keras.saving.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.saving.saved_model.load.Dense object at 0x7f1a2dd3aed0> has the same name 'Dense' as a built-in Keras object. Consider renaming <class 'keras.saving.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeTl15C289ZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04fb79a-1a2b-4b9e-ac6a-f715005462b4"
      },
      "source": [
        "model.evaluate(testgen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "877/877 [==============================] - 287s 327ms/step - loss: 0.0057 - accuracy: 0.9989\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.005700704175978899, 0.9988597631454468]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "cJbPurSt-xl2",
        "outputId": "d613e865-6d1e-42cd-840f-0cc0a18961b5"
      },
      "source": [
        "# Further fitting, very low lr\n",
        "super_final_fit = True\n",
        "if super_final_fit:\n",
        "  # Unfreeze also your mom\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "  # Lr so low\n",
        "  from tensorflow.keras.optimizers import Adam\n",
        "  model.compile(optimizer=Adam(learning_rate=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  model.fit(traingen, epochs=13, steps_per_epoch=n_steps,  batch_size=BATCH_SIZE, validation_data=validgen)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "465/465 [==============================] - 2886s 6s/step - loss: 0.1643 - accuracy: 0.9478 - val_loss: 0.3156 - val_accuracy: 0.9186\n",
            "Epoch 2/15\n",
            "465/465 [==============================] - 801s 2s/step - loss: 0.1195 - accuracy: 0.9621 - val_loss: 0.2526 - val_accuracy: 0.9271\n",
            "Epoch 3/15\n",
            "465/465 [==============================] - 800s 2s/step - loss: 0.1095 - accuracy: 0.9647 - val_loss: 0.2390 - val_accuracy: 0.9314\n",
            "Epoch 4/15\n",
            "465/465 [==============================] - 800s 2s/step - loss: 0.1028 - accuracy: 0.9672 - val_loss: 0.2702 - val_accuracy: 0.9259\n",
            "Epoch 5/15\n",
            "465/465 [==============================] - 801s 2s/step - loss: 0.1048 - accuracy: 0.9680 - val_loss: 0.2223 - val_accuracy: 0.9326\n",
            "Epoch 6/15\n",
            "465/465 [==============================] - 802s 2s/step - loss: 0.0930 - accuracy: 0.9715 - val_loss: 0.1739 - val_accuracy: 0.9496\n",
            "Epoch 7/15\n",
            "465/465 [==============================] - 801s 2s/step - loss: 0.0870 - accuracy: 0.9720 - val_loss: 0.1646 - val_accuracy: 0.9460\n",
            "Epoch 8/15\n",
            "465/465 [==============================] - 801s 2s/step - loss: 0.0821 - accuracy: 0.9737 - val_loss: 0.1531 - val_accuracy: 0.9508\n",
            "Epoch 9/15\n",
            "465/465 [==============================] - 801s 2s/step - loss: 0.0800 - accuracy: 0.9737 - val_loss: 0.1697 - val_accuracy: 0.9514\n",
            "Epoch 10/15\n",
            "465/465 [==============================] - 800s 2s/step - loss: 0.0828 - accuracy: 0.9727 - val_loss: 0.1697 - val_accuracy: 0.9484\n",
            "Epoch 11/15\n",
            "465/465 [==============================] - 799s 2s/step - loss: 0.0752 - accuracy: 0.9757 - val_loss: 0.1366 - val_accuracy: 0.9575\n",
            "Epoch 12/15\n",
            "465/465 [==============================] - 791s 2s/step - loss: 0.0741 - accuracy: 0.9758 - val_loss: 0.1297 - val_accuracy: 0.9599\n",
            "Epoch 13/15\n",
            "465/465 [==============================] - 791s 2s/step - loss: 0.0704 - accuracy: 0.9767 - val_loss: 0.1050 - val_accuracy: 0.9654\n",
            "Epoch 14/15\n",
            " 28/465 [>.............................] - ETA: 11:44 - loss: 0.0895 - accuracy: 0.9699"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-a2dcaa373d23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraingen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeVywZgllaTi",
        "outputId": "88162518-4637-4e9d-fd2d-edd11bc11344"
      },
      "source": [
        "if super_final_fit:\n",
        "  model.save(\"xception_super_final\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: xception_super_final/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n",
            "WARNING:absl:<keras.saving.saved_model.load.Dense object at 0x7f3cb3439910> has the same name 'Dense' as a built-in Keras object. Consider renaming <class 'keras.saving.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.saving.saved_model.load.Dense object at 0x7f3cb343fbd0> has the same name 'Dense' as a built-in Keras object. Consider renaming <class 'keras.saving.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.saving.saved_model.load.Dense object at 0x7f3cb343fc90> has the same name 'Dense' as a built-in Keras object. Consider renaming <class 'keras.saving.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBLuZvP6yMz6"
      },
      "source": [
        "load_super_final_fit = True\n",
        "if load_super_final_fit:\n",
        "  super_final_fit = True\n",
        "  model = tf.keras.models.load_model(\"xception_super_final\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4UbdyDolCap",
        "outputId": "9ff14d99-aa04-4106-cd08-2b6f85a841d5"
      },
      "source": [
        "if super_final_fit:\n",
        "  from keras import backend as K\n",
        "  K.set_value(model.optimizer.learning_rate, 5e-6)\n",
        "  backup3 = tf.keras.callbacks.experimental.BackupAndRestore(\n",
        "    \"xception_final_cut_backup\"\n",
        "  )\n",
        "  model.fit(traingen, epochs=15, steps_per_epoch=n_steps,  batch_size=BATCH_SIZE, validation_data=validgen, callbacks=backup3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "187/465 [===========>..................] - ETA: 1:13:47 - loss: 0.0826 - accuracy: 0.9753"
          ]
        }
      ]
    }
  ]
}