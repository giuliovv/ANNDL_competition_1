{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuliovv/ANNDL_competition_1/blob/master/giulio_models/xception_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unzip and import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-35gnQG8yoS",
        "outputId": "aba82e97-2160-4805-f1af-cdd657789972"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "colab = \"True\" #@param ['True','False']\n",
        "if colab == \"True\":\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "  %cd /gdrive/MyDrive/Colab Notebooks\n",
        "  if not os.path.isdir('training'):\n",
        "    !unzip dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kad8mvnp85ML"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QC8765_k1smh"
      },
      "outputs": [],
      "source": [
        "labels = ['Apple','Blueberry','Cherry','Corn','Grape','Orange','Peach','Pepper','Potato','Raspberry','Soybean','Squash','Strawberry','Tomato']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsUbDe48D-Dt",
        "outputId": "a86b4386-b49c-43ac-f8f6-92e07cb6a0af"
      },
      "outputs": [],
      "source": [
        "y = tf.keras.utils.to_categorical(range(len(labels)))\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split data in train and test\n",
        "Build a test folder, we also tried with the plant_village dataset without good results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSqVl1baOwjs"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "get_plants = False\n",
        "\n",
        "if not \"test\" in os.listdir():\n",
        "  # Build the test dataset\n",
        "  print(\"No test directory!\")\n",
        "  for label in labels:\n",
        "    print(label)\n",
        "    image_names = [pic for pic in os.listdir(\"training/\"+label)]\n",
        "    train_images, test_images = train_test_split(image_names, test_size=0.05)\n",
        "    if not 'test/'+label in os.listdir():\n",
        "      try:\n",
        "        os.makedirs(os.path.abspath(os.getcwd())+'/test/'+label+'/')\n",
        "      except OSError:\n",
        "        print(\"Failed to create a dir for \", '/test/'+label+'/')\n",
        "      else:\n",
        "        print(\"Success creating folder \", label)\n",
        "    for name in test_images:\n",
        "      shutil.move(os.path.abspath(os.getcwd())+'/training/'+label+'/'+name, os.path.abspath(os.getcwd())+'/test/'+label+'/'+name)\n",
        "  print(\"Transfered all testing data!\")\n",
        "\n",
        "if get_plants:\n",
        "  # Get plant_village dataset\n",
        "  ! pip install -q tfds-nightly\n",
        "  import tensorflow_datasets as tfds\n",
        "  from PIL import Image\n",
        "  ds = tfds.load('plant_village', split='train')\n",
        "  builder = tfds.builder('plant_village')\n",
        "  info = builder.info\n",
        "  labels_tf = info.features[\"label\"].names\n",
        "  if not 'test_expanded/' in os.listdir():\n",
        "      try:\n",
        "        os.makedirs(os.path.abspath(os.getcwd())+'/test_expanded/')\n",
        "      except OSError:\n",
        "        print(\"Failed to create a dir for /test_expanded/\")\n",
        "      else:\n",
        "        print(\"Success creating folder test_expanded\")\n",
        "  image_number = 54303\n",
        "  ds = ds.take(54303)\n",
        "  for el in ds:\n",
        "    label_new_ds = labels_tf[el[\"label\"].numpy()]\n",
        "    for just_fruit_name in labels:\n",
        "      if just_fruit_name in label_new_ds:\n",
        "        if not just_fruit_name in os.listdir(\"test_expanded\"):\n",
        "          try:\n",
        "            os.makedirs(os.path.abspath(os.getcwd())+'/test_expanded/'+just_fruit_name+'/')\n",
        "          except OSError:\n",
        "            print(\"Failed to create a dir for \", '/test_expanded/'+just_fruit_name+'/')\n",
        "          else:\n",
        "            print(\"Success creating folder \", just_fruit_name)\n",
        "        im = Image.fromarray(el[\"image\"].numpy())\n",
        "        im.save(os.path.abspath(os.getcwd())+'/test_expanded/'+just_fruit_name+\"/\"+str(image_number)+\".jpeg\")\n",
        "        break\n",
        "    if image_number % 1000 == 0:\n",
        "      print(image_number)\n",
        "    image_number += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing and augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WDFJ3xEckxa"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def preproc(img):\n",
        "  '''Add random noise to an image'''\n",
        "  VARIABILITY = 50\n",
        "  deviation = VARIABILITY*random.random()\n",
        "  noise = np.random.normal(0, deviation, img.shape)\n",
        "  img += noise\n",
        "  np.clip(img, 0., 255.)\n",
        "  X = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "  return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO-nIcaRTU1a",
        "outputId": "ef92c82d-600a-432d-91e8-bdc81bd6b834"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "VALIDATE_BATCH_SIZE = BATCH_SIZE\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "                                    rotation_range=90,\n",
        "                                    fill_mode='nearest',\n",
        "                                    brightness_range=(0.2,1.8),\n",
        "                                    channel_shift_range=150,\n",
        "                                    shear_range=0.7,\n",
        "                                    zoom_range=0.5,\n",
        "                                    width_shift_range=0.3, \n",
        "                                    height_shift_range=0.3,\n",
        "                                    horizontal_flip=True, \n",
        "                                    vertical_flip=True,\n",
        "                                    validation_split=0.05,\n",
        "                                    preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
        "test_generator = ImageDataGenerator(preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
        "\n",
        "traingen = train_generator.flow_from_directory('training',\n",
        "                                              target_size=(256, 256),\n",
        "                                              class_mode='categorical',\n",
        "                                              classes=labels,\n",
        "                                              subset='training',\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              seed=42)\n",
        "\n",
        "validgen = train_generator.flow_from_directory('training',\n",
        "                                              target_size=(256, 256),\n",
        "                                              class_mode='categorical',\n",
        "                                              classes=labels,\n",
        "                                              subset='validation',\n",
        "                                              batch_size=VALIDATE_BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              seed=42)\n",
        "\n",
        "testgen = test_generator.flow_from_directory('test',\n",
        "                                            target_size=(256, 256),\n",
        "                                            class_mode='categorical',\n",
        "                                            classes=labels,\n",
        "                                            batch_size=1,\n",
        "                                            shuffle=False,\n",
        "                                            seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from  sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "            class_weight='balanced',\n",
        "            classes=np.unique(traingen.classes), \n",
        "            y=traingen.classes)\n",
        "# Keras requires a dictionary\n",
        "class_weights = {i : class_weights[i] for i in range(len(class_weights))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1qX2Yha_XmP"
      },
      "outputs": [],
      "source": [
        "n_steps = traingen.samples / BATCH_SIZE\n",
        "n_val_steps = validgen.samples / VALIDATE_BATCH_SIZE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also tried VGG16, Inception and Nasnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeECwxYABRW7",
        "outputId": "072899b4-09da-42bb-e8bc-b6e91ab7bba9"
      },
      "outputs": [],
      "source": [
        "# create the base pre-trained model\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=(256, 256,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Po279iIMCB8Z"
      },
      "outputs": [],
      "source": [
        "n_classes = len(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This net is the last we tried with also Gaussian noise, our best results where with the same model but without Gaussian noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3zgOshuBT7o"
      },
      "outputs": [],
      "source": [
        "lrelu = lambda x: tf.keras.activations.relu(x, alpha=0.01)\n",
        "\n",
        "inputs = tf.keras.Input(shape=(256, 256, 3))\n",
        "inputs = tf.keras.layers.GaussianNoise(20)(inputs)\n",
        "\n",
        "x = base_model(inputs, training=False)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = Dense(1024, activation=lrelu, name=\"first\")(x)\n",
        "x = Dense(512, activation=lrelu, name=\"second\")(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dropout(0.8)(x)\n",
        "x = Dense(512, activation=lrelu, name=\"third\")(x)\n",
        "predictions = Dense(n_classes, activation='softmax', name=\"last\")(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wsxV1pEB5Nq"
      },
      "outputs": [],
      "source": [
        "# Train only the randomly initialized layers (which were not part of the pre-trained model)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Iw3p86sGTXh"
      },
      "outputs": [],
      "source": [
        "callbacks = []\n",
        "\n",
        "early_stop = True\n",
        "if early_stop:\n",
        "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)\n",
        "    callbacks.append(es_callback)\n",
        "    \n",
        "lr_plateau_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    min_lr=0,\n",
        ")  \n",
        "\n",
        "callbacks.append(lr_plateau_callback)\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\", histogram_freq=1)\n",
        "\n",
        "callbacks.append(tensorboard_callback)\n",
        "\n",
        "backup = tf.keras.callbacks.experimental.BackupAndRestore(\n",
        "    \"xception_noise_top_only_backup\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQXQ6gs7P-m9"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "CnoXtvRUP_Dz",
        "outputId": "d22d384d-1b81-4e08-f2fe-34dd15bd8bb8"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir \"./logs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfNRHFoGCRYR",
        "outputId": "921a3230-a3e6-4bfa-bcd0-9a84ab0542c4"
      },
      "outputs": [],
      "source": [
        "model.fit(traingen, epochs=12, steps_per_epoch=n_steps, batch_size=BATCH_SIZE, validation_data=validgen, callbacks=callbacks+[backup], class_weight=class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JplAsf-d9Hi",
        "outputId": "970cfb51-5567-439f-cd0f-780929aa9a4a"
      },
      "outputs": [],
      "source": [
        "model.save(\"xception_noise_only_top\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqiycAJLJIrG",
        "outputId": "5ef8ecce-99a4-49c3-9cc4-9dbfdf4013ce"
      },
      "outputs": [],
      "source": [
        "# at this point, the top layers are well trained and we can start fine-tuning\n",
        "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
        "# and train the remaining top layers.\n",
        "\n",
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDbD1NeQYMDA",
        "outputId": "780e1255-e2ec-4c76-aeaa-39e71e1fb101"
      },
      "outputs": [],
      "source": [
        "# We tried also unfreezing a different number of layers but the results were worse.\n",
        "for layer in model.layers[:50]:\n",
        "  layer.trainable = False\n",
        "for layer in model.layers[50:]:\n",
        "  layer.trainable = True\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# The other callbacks are the same but we need a new backup folder\n",
        "backup2 = tf.keras.callbacks.experimental.BackupAndRestore(\n",
        "    \"xception_second_part_backup_noise\"\n",
        ")\n",
        "\n",
        "# Train again fine tuning also some xception layers\n",
        "model.fit(traingen, epochs=15, steps_per_epoch=n_steps,  batch_size=BATCH_SIZE, validation_data=validgen, callbacks=callbacks+[backup2], class_weight=class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXeZeBLzeDz3"
      },
      "outputs": [],
      "source": [
        "model.save(\"xception_noise\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeTl15C289ZK"
      },
      "outputs": [],
      "source": [
        "model.evaluate(testgen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJbPurSt-xl2"
      },
      "outputs": [],
      "source": [
        "# Further fitting, very low lr\n",
        "super_final_fit = False\n",
        "if super_final_fit:\n",
        "  model = tf.keras.models.load_model(\"xception\")\n",
        "\n",
        "  # Unfreeze everything\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "  # Lr so low\n",
        "  from tensorflow.keras.optimizers import Adam\n",
        "  model.compile(optimizer=Adam(learning_rate=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jGoSrICSQsr"
      },
      "outputs": [],
      "source": [
        "if super_final_fit:\n",
        "  model.fit(traingen, epochs=13, steps_per_epoch=n_steps,  batch_size=BATCH_SIZE, validation_data=validgen, class_weight=class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeVywZgllaTi"
      },
      "outputs": [],
      "source": [
        "if super_final_fit:\n",
        "  model.save(\"xception_super_final\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "competition_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
