{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nasnet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuliovv/ANNDL_competition_1/blob/master/giulio_models/nasnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_YKwihCmODh",
        "outputId": "335dcba5-6998-46e6-c5bc-3121b11b5fdd"
      },
      "source": [
        "import os\n",
        "\n",
        "colab = \"True\" #@param ['True','False']\n",
        "if colab == \"True\":\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "  %cd /gdrive/MyDrive/Colab Notebooks/\n",
        "  if not os.path.isdir('training'):\n",
        "    !unzip dataset.zip\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQi-KfSvmVd1"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOoEQRQmnIN4"
      },
      "source": [
        "dataset_dir = 'training'\n",
        "labels = ['Apple','Blueberry','Cherry','Corn','Grape','Orange','Peach','Pepper','Potato','Raspberry','Soybean','Squash','Strawberry','Tomato']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3M_KohRnLDt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm_COPn1nNo5"
      },
      "source": [
        "import shutil\n",
        "if not \"test\" in os.listdir():\n",
        "  print(\"No test directory!\")\n",
        "  for label in labels:\n",
        "    print(label)\n",
        "    image_names = [pic for pic in os.listdir(\"training/\"+label)]\n",
        "    train_images, test_images = train_test_split(image_names, test_size=0.05)\n",
        "    if not 'test/'+label in os.listdir():\n",
        "      try:\n",
        "        os.makedirs(os.path.abspath(os.getcwd())+'/test/'+label+'/')\n",
        "      except OSError:\n",
        "        print(\"Failed to create a dir for \", '/test/'+label+'/')\n",
        "      else:\n",
        "        print(\"Success creating folder \", label)\n",
        "    for name in test_images:\n",
        "      shutil.move(os.path.abspath(os.getcwd())+'/training/'+label+'/'+name, os.path.abspath(os.getcwd())+'/test/'+label+'/'+name)\n",
        "  print(\"Transfered all testing data!\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqh6gqMwnSL_"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.nasnet import NASNetMobile\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqzqEF2kn61X",
        "outputId": "3e92e012-5858-47b1-af23-951e415891dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "VALIDATE_BATCH_SIZE = BATCH_SIZE\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "## when rotating some pixels remain unfilled, to fill them the default function is to take the \"nearest pixel color\", this maybe screws up the learning process so I left it for later training\n",
        "                                    rotation_range=10,\n",
        "                                    fill_mode='nearest',\n",
        "                                    brightness_range=(0.6,1.4),\n",
        "                                    channel_shift_range=150,\n",
        "                                    shear_range=0.2,\n",
        "                                    zoom_range=0.2,\n",
        "                                    width_shift_range=0.1, \n",
        "                                    height_shift_range=0.1,\n",
        "                                    horizontal_flip=True, \n",
        "                                    vertical_flip=True,\n",
        "                                    validation_split=0.2,\n",
        "                                    preprocessing_function=tf.keras.applications.inception_v3.preprocess_input) # VGG16 preprocessing\n",
        "test_generator = ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_v3.preprocess_input)\n",
        "\n",
        "traingen = train_generator.flow_from_directory('training',\n",
        "                                              target_size=(256, 256),\n",
        "                                              class_mode='categorical',\n",
        "                                              classes=labels,\n",
        "                                              subset='training',\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              seed=42)\n",
        "\n",
        "validgen = train_generator.flow_from_directory('training',\n",
        "                                              target_size=(256, 256),\n",
        "                                              class_mode='categorical',\n",
        "                                              classes=labels,\n",
        "                                              subset='validation',\n",
        "                                              batch_size=VALIDATE_BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              seed=42)\n",
        "\n",
        "testgen = test_generator.flow_from_directory('test',\n",
        "                                            target_size=(256, 256),\n",
        "                                            class_mode='categorical',\n",
        "                                            classes=labels,\n",
        "                                            batch_size=1,\n",
        "                                            shuffle=False,\n",
        "                                            seed=42)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 13238 images belonging to 14 classes.\n",
            "Found 3301 images belonging to 14 classes.\n",
            "Found 877 images belonging to 14 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfwZGt5goYHZ",
        "outputId": "be8661e8-009d-4a9b-8b83-a61d2f6c97d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "base_model = NASNetMobile(weights='imagenet', include_top=False, input_shape=(256, 256,3))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a2f011b08d04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNASNetMobile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/applications/nasnet.py\u001b[0m in \u001b[0;36mNASNetMobile\u001b[0;34m(input_shape, include_top, weights, input_tensor, pooling, classes)\u001b[0m\n\u001b[1;32m    396\u001b[0m       \u001b[0mpooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpooling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m       \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m       default_size=224)\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/applications/nasnet.py\u001b[0m in \u001b[0;36mNASNet\u001b[0;34m(input_shape, penultimate_filters, num_blocks, stem_block_filters, skip_reduction, filter_multiplier, include_top, weights, input_tensor, pooling, classes, default_size, classifier_activation)\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       weights=weights)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'channels_last'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdefault_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         raise ValueError('When setting `include_top=True` '\n\u001b[0m\u001b[1;32m    350\u001b[0m                          \u001b[0;34m'and loading `imagenet` weights, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                          \u001b[0;34mf'`input_shape` should be {default_shape}.  '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (224, 224, 3).  Received: input_shape=(256, 256, 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VSv-SAooud9"
      },
      "source": [
        "n_classes = len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_4vCERWozjn"
      },
      "source": [
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "# and a logistic layer -- let's say we have n_classes classes\n",
        "predictions = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SipmfsZo1AH"
      },
      "source": [
        "# Freeze original layers\n",
        "model.trainable = True    \n",
        "set_trainable = False\n",
        "for layer in model.layers:\n",
        "  if layer.name == 'activation_166':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False\n",
        "  print(\"layer {} is {}\".format(layer.name, '+++trainable' if layer.trainable else '---frozen'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phFnA2vDxJfg"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v5zRU_Exj_5"
      },
      "source": [
        "callbacks = []\n",
        "\n",
        "early_stop = True\n",
        "if early_stop:\n",
        "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)\n",
        "    callbacks.append(es_callback)\n",
        "    \n",
        "#LRPlateau\n",
        "lr_plateau_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    min_lr=0,\n",
        ")  \n",
        "\n",
        "callbacks.append(lr_plateau_callback)\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\", histogram_freq=1)\n",
        "\n",
        "callbacks.append(tensorboard_callback)\n",
        "\n",
        "backup = tf.keras.callbacks.experimental.BackupAndRestore(\n",
        "    \"backup_nasnet\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXIPoCVoxmHu"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOCIi59oxpuN"
      },
      "source": [
        "%tensorboard --logdir \"./logs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2p1WnB1xrXc"
      },
      "source": [
        "n_steps = traingen.samples / BATCH_SIZE\n",
        "n_val_steps = validgen.samples / VALIDATE_BATCH_SIZE\n",
        "\n",
        "model.fit(traingen, epochs=25, steps_per_epoch=10,  batch_size=128, validation_data=validgen, callbacks=callbacks+[backup2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mifz8wh4zDU1"
      },
      "source": [
        "model.save(\"nasnet\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}