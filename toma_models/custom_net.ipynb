{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuliovv/ANNDL_competition_1/blob/master/toma_models/custom_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xahQdYrOFCqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e70d1d3f-0a5d-4473-9bee-3dc43600b2b5"
      },
      "source": [
        "import os\n",
        "\n",
        "colab = \"True\" #@param ['True','False']\n",
        "if colab == \"True\":\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "  %cd /gdrive/MyDrive/Colab Notebooks\n",
        "  if not os.path.isdir('training'):\n",
        "    !unzip dataset.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlSNLNuWFE6u"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDKny82hFLPI"
      },
      "source": [
        "dataset_dir = 'training'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM9KKiUUFM2v"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph22TKplFQEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4253b7df-7960-4299-b81e-226fae37fb8c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "labels = ['Apple','Blueberry','Cherry','Corn','Grape','Orange','Peach','Pepper','Potato','Raspberry','Soybean','Squash','Strawberry','Tomato']\n",
        "y = tf.keras.utils.to_categorical(range(len(labels)))\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQS3BUanFV8x"
      },
      "source": [
        "import shutil\n",
        "\n",
        "get_plants = False\n",
        "\n",
        "if not \"test\" in os.listdir():\n",
        "  print(\"No test directory!\")\n",
        "  for label in labels:\n",
        "    print(label)\n",
        "    image_names = [pic for pic in os.listdir(\"training/\"+label)]\n",
        "    train_images, test_images = train_test_split(image_names, test_size=0.05)\n",
        "    if not 'test/'+label in os.listdir():\n",
        "      try:\n",
        "        os.makedirs(os.path.abspath(os.getcwd())+'/test/'+label+'/')\n",
        "      except OSError:\n",
        "        print(\"Failed to create a dir for \", '/test/'+label+'/')\n",
        "      else:\n",
        "        print(\"Success creating folder \", label)\n",
        "    for name in test_images:\n",
        "      shutil.move(os.path.abspath(os.getcwd())+'/training/'+label+'/'+name, os.path.abspath(os.getcwd())+'/test/'+label+'/'+name)\n",
        "  print(\"Transfered all testing data!\")\n",
        "\n",
        "if get_plants:\n",
        "  ! pip install -q tfds-nightly\n",
        "  import tensorflow_datasets as tfds\n",
        "  from PIL import Image\n",
        "  ds = tfds.load('plant_village', split='train')\n",
        "  builder = tfds.builder('plant_village')\n",
        "  info = builder.info\n",
        "  labels_tf = info.features[\"label\"].names\n",
        "  if not 'test_expanded/' in os.listdir():\n",
        "      try:\n",
        "        os.makedirs(os.path.abspath(os.getcwd())+'/test_expanded/')\n",
        "      except OSError:\n",
        "        print(\"Failed to create a dir for /test_expanded/\")\n",
        "      else:\n",
        "        print(\"Success creating folder test_expanded\")\n",
        "  image_number = 54303\n",
        "  ds = ds.take(54303)\n",
        "  for el in ds:\n",
        "    label_new_ds = labels_tf[el[\"label\"].numpy()]\n",
        "    for just_fruit_name in labels:\n",
        "      if just_fruit_name in label_new_ds:\n",
        "        if not just_fruit_name in os.listdir(\"test_expanded\"):\n",
        "          try:\n",
        "            os.makedirs(os.path.abspath(os.getcwd())+'/test_expanded/'+just_fruit_name+'/')\n",
        "          except OSError:\n",
        "            print(\"Failed to create a dir for \", '/test_expanded/'+just_fruit_name+'/')\n",
        "          else:\n",
        "            print(\"Success creating folder \", just_fruit_name)\n",
        "        im = Image.fromarray(el[\"image\"].numpy())\n",
        "        im.save(os.path.abspath(os.getcwd())+'/test_expanded/'+just_fruit_name+\"/\"+str(image_number)+\".jpeg\")\n",
        "        break\n",
        "    if image_number % 1000 == 0:\n",
        "      print(image_number)\n",
        "    image_number += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b_ueylaFYTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6039fc57-6e14-406f-a6a4-75c4ede55352"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "VALIDATE_BATCH_SIZE = BATCH_SIZE\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "## when rotating some pixels remain unfilled, to fill them the default function is to take the \"nearest pixel color\", this maybe screws up the learning process so I left it for later training\n",
        "                                    #featurewise_center=True,\n",
        "                                    #featurewise_std_normalization=True,\n",
        "                                    rotation_range=90,\n",
        "                                    fill_mode='nearest',\n",
        "                                    brightness_range=(0.2,1.8),\n",
        "                                    channel_shift_range=150,\n",
        "                                    shear_range=0.7,\n",
        "                                    zoom_range=0.5,\n",
        "                                    width_shift_range=0.5, \n",
        "                                    height_shift_range=0.5,\n",
        "                                    horizontal_flip=True, \n",
        "                                    vertical_flip=True,\n",
        "                                    validation_split=0.1,\n",
        "                                    preprocessing_function=tf.keras.applications.xception.preprocess_input) # VGG16 preprocessing\n",
        "test_generator = ImageDataGenerator(preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
        "\n",
        "\n",
        "#train_generator.fit(X, seed=42)\n",
        "\n",
        "traingen = train_generator.flow_from_directory('training',\n",
        "                                              target_size=(256, 256),\n",
        "                                              class_mode='categorical',\n",
        "                                              classes=labels,\n",
        "                                              subset='training',\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              seed=42)\n",
        "\n",
        "validgen = train_generator.flow_from_directory('training',\n",
        "                                              target_size=(256, 256),\n",
        "                                              class_mode='categorical',\n",
        "                                              classes=labels,\n",
        "                                              subset='validation',\n",
        "                                              batch_size=VALIDATE_BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              seed=42)\n",
        "\n",
        "testgen = test_generator.flow_from_directory('test',\n",
        "                                            target_size=(256, 256),\n",
        "                                            class_mode='categorical',\n",
        "                                            classes=labels,\n",
        "                                            batch_size=1,\n",
        "                                            shuffle=False,\n",
        "                                            seed=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15158 images belonging to 14 classes.\n",
            "Found 1677 images belonging to 14 classes.\n",
            "Found 893 images belonging to 14 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q648eAtFajy"
      },
      "source": [
        "n_steps = traingen.samples / BATCH_SIZE\n",
        "n_val_steps = validgen.samples / VALIDATE_BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohZR76UwFeEI"
      },
      "source": [
        "n_classes = len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlhzpkfXFfzj"
      },
      "source": [
        "load = False\n",
        "\n",
        "if load:\n",
        "  model = tf.keras.models.load_model(\"custom_net_backup\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5AfRmgAsAT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5761552a-0812-438d-f38d-5f77a07259ab"
      },
      "source": [
        "import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def make_model(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [128, 256, 512, 728]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(512, activation=\"relu\")(x)\n",
        "\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "model = make_model(input_shape=(256,256,3), num_classes=n_classes)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " rescaling_2 (Rescaling)        (None, 64, 64, 3)    0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 32, 32)   896         ['rescaling_2[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 32, 32, 32)  128         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 32, 32, 64)   18496       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 32, 32, 64)  256         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 32, 32, 64)   0           ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " separable_conv2d_18 (Separable  (None, 32, 32, 128)  8896       ['activation_24[0][0]']          \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 32, 32, 128)  512        ['separable_conv2d_18[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " separable_conv2d_19 (Separable  (None, 32, 32, 128)  17664      ['activation_25[0][0]']          \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 32, 32, 128)  512        ['separable_conv2d_19[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (None, 16, 16, 128)  0          ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 128)  8320        ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 16, 16, 128)  0           ['max_pooling2d_8[0][0]',        \n",
            "                                                                  'conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 16, 16, 128)  0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " separable_conv2d_20 (Separable  (None, 16, 16, 256)  34176      ['activation_26[0][0]']          \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 16, 16, 256)  1024       ['separable_conv2d_20[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " separable_conv2d_21 (Separable  (None, 16, 16, 256)  68096      ['activation_27[0][0]']          \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 16, 16, 256)  1024       ['separable_conv2d_21[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPooling2D)  (None, 8, 8, 256)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 8, 8, 256)    33024       ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 8, 8, 256)    0           ['max_pooling2d_9[0][0]',        \n",
            "                                                                  'conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 8, 8, 256)    0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " separable_conv2d_22 (Separable  (None, 8, 8, 512)   133888      ['activation_28[0][0]']          \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 8, 8, 512)   2048        ['separable_conv2d_22[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 8, 8, 512)    0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " separable_conv2d_23 (Separable  (None, 8, 8, 512)   267264      ['activation_29[0][0]']          \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 8, 8, 512)   2048        ['separable_conv2d_23[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooling2D  (None, 4, 4, 512)   0           ['batch_normalization_29[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 4, 4, 512)    131584      ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 4, 4, 512)    0           ['max_pooling2d_10[0][0]',       \n",
            "                                                                  'conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 4, 4, 512)    0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " separable_conv2d_24 (Separable  (None, 4, 4, 728)   378072      ['activation_30[0][0]']          \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 4, 4, 728)   2912        ['separable_conv2d_24[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 4, 4, 728)    0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " separable_conv2d_25 (Separable  (None, 4, 4, 728)   537264      ['activation_31[0][0]']          \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 4, 4, 728)   2912        ['separable_conv2d_25[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooling2D  (None, 2, 2, 728)   0           ['batch_normalization_31[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 2, 2, 728)    373464      ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 2, 2, 728)    0           ['max_pooling2d_11[0][0]',       \n",
            "                                                                  'conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " separable_conv2d_26 (Separable  (None, 2, 2, 1024)  753048      ['add_11[0][0]']                 \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 2, 2, 1024)  4096        ['separable_conv2d_26[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 2, 2, 1024)   0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2 (Gl  (None, 1024)        0           ['activation_32[0][0]']          \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 1024)         0           ['global_average_pooling2d_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 1024)         0           ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 14)           14350       ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,795,974\n",
            "Trainable params: 2,787,238\n",
            "Non-trainable params: 8,736\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcCQHg7gFi7F"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GyJXWlxFkrr"
      },
      "source": [
        "callbacks = []\n",
        "\n",
        "early_stop = True\n",
        "if early_stop:\n",
        "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)\n",
        "    callbacks.append(es_callback)\n",
        "    \n",
        "#LRPlateau\n",
        "lr_plateau_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    min_lr=0,\n",
        ")  \n",
        "\n",
        "callbacks.append(lr_plateau_callback)\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\", histogram_freq=1)\n",
        "\n",
        "callbacks.append(tensorboard_callback)\n",
        "\n",
        "backup = tf.keras.callbacks.experimental.BackupAndRestore(\n",
        "    \"custom_net_backup\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12BJPCFsFmK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf90808e-574d-4f56-8472-d5e75175b707"
      },
      "source": [
        "model.fit(traingen, epochs=6, steps_per_epoch=n_steps, batch_size=BATCH_SIZE, validation_data=validgen, callbacks=callbacks+[backup])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk-5kxEdFoE3"
      },
      "source": [
        "if not load:\n",
        "  model.save(\"custom_net_backup\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJl6XS0tF9oa"
      },
      "source": [
        "model.evaluate(testgen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqvifRGxGIww"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}